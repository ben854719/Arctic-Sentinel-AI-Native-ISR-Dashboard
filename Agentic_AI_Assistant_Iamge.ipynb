{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyPImFfCnzhRDH1UzcSCLsSB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ben854719/Arctic-Sentinel-AI-Native-ISR-Dashboard/blob/main/Agentic_AI_Assistant_Iamge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ucs95d3osTdv",
        "outputId": "5acf2d53-556e-4e3a-e4ae-5572cb9b2f23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (2.0.10)\n",
            "Collecting langchain-google-genai\n",
            "  Using cached langchain_google_genai-3.0.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Collecting google-ai-generativelanguage<1.0.0,>=0.7.0 (from langchain-google-genai)\n",
            "  Using cached google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain-google-genai)\n",
            "  Using cached langchain_core-1.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.11.10)\n",
            "INFO: pip is looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-generativeai\n",
            "  Using cached google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Using cached google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.8.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: pip is still looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached google_generativeai-0.8.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.8.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "  Using cached google_generativeai-0.7.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.7.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.6.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Using cached google_generativeai-0.4.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Using cached google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached google_generativeai-0.3.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached google_generativeai-0.3.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Using cached google_generativeai-0.2.2-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Using cached google_generativeai-0.2.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Using cached google_generativeai-0.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Using cached google_generativeai-0.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Using cached langchain_google_genai-3.0.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_google_genai-3.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain_google_genai-3.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-core>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.3.79)\n",
            "  Using cached langchain_google_genai-2.1.11-py3-none-any.whl.metadata (6.7 kB)\n",
            "  Using cached langchain_google_genai-2.1.10-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Using cached langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Using cached langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Using cached langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Using cached langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Using cached langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Using cached langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Using cached langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Using cached langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Using cached langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Using cached langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (0.4.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (6.0.3)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.3.75->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.25.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.10.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (2.0.10)\n",
            "Collecting langchain-google-genai\n",
            "  Using cached langchain_google_genai-3.0.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.1)\n",
            "Collecting langgraph\n",
            "  Using cached langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Collecting google-ai-generativelanguage<1.0.0,>=0.7.0 (from langchain-google-genai)\n",
            "  Using cached google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain-google-genai)\n",
            "  Using cached langchain_core-1.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.11.10)\n",
            "INFO: pip is looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-generativeai\n",
            "  Using cached google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Using cached google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.8.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: pip is still looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached google_generativeai-0.8.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.8.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "  Using cached google_generativeai-0.7.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.7.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.6.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Using cached google_generativeai-0.4.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Using cached google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached google_generativeai-0.3.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached google_generativeai-0.3.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Using cached google_generativeai-0.2.2-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Using cached google_generativeai-0.2.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Using cached google_generativeai-0.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Using cached google_generativeai-0.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Using cached langchain_google_genai-3.0.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_google_genai-3.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain_google_genai-3.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-core>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.3.79)\n",
            "  Using cached langchain_google_genai-2.1.11-py3-none-any.whl.metadata (6.7 kB)\n",
            "  Using cached langchain_google_genai-2.1.10-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Using cached langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Using cached langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Using cached langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Using cached langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Using cached langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Using cached langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Using cached langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Using cached langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Using cached langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Using cached langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.1)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
            "  Using cached langgraph_prebuilt-1.0.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (0.4.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (6.0.3)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
            "INFO: pip is looking at multiple versions of langgraph-prebuilt to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached langgraph_prebuilt-1.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Using cached langgraph_prebuilt-1.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Using cached langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Using cached langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "INFO: pip is still looking at multiple versions of langgraph-prebuilt to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Using cached langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph\n",
            "  Using cached langgraph-1.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.1)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.3.75->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.25.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.12/dist-packages (0.4.42)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith) (3.11.4)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langsmith) (25.0)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langsmith) (2.11.10)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade langchain-google-genai google-generativeai\n",
        "!pip install --upgrade langchain-google-genai google-generativeai langgraph\n",
        "!pip install langsmith"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = \"LangSmith\""
      ],
      "metadata": {
        "id": "1FQogh-4xnwJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"mcp[cli]\"\n",
        "from mcp.server.fastmcp import FastMCP\n",
        "\n",
        "mcp = FastMCP(\"GeminiTools\")\n",
        "\n",
        "@mcp.tool()\n",
        "def search(query: str) -> list:\n",
        "    # Your search logic here\n",
        "    return [\"Result 1\", \"Result 2\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OyiHKaWsymKB",
        "outputId": "64321a17-1880-4048-dd9f-7e3d432adfa1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mcp[cli] in /usr/local/lib/python3.12/dist-packages (1.21.0)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.12/dist-packages (from mcp[cli]) (4.11.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp[cli]) (0.4.3)\n",
            "Requirement already satisfied: httpx>=0.27.1 in /usr/local/lib/python3.12/dist-packages (from mcp[cli]) (0.28.1)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp[cli]) (4.25.1)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp[cli]) (2.12.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.11.0 in /usr/local/lib/python3.12/dist-packages (from mcp[cli]) (2.11.10)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp[cli]) (2.10.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp[cli]) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp[cli]) (3.0.3)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp[cli]) (0.49.3)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp[cli]) (0.38.0)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from mcp[cli]) (1.2.1)\n",
            "Requirement already satisfied: typer>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from mcp[cli]) (0.20.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio>=4.5->mcp[cli]) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio>=4.5->mcp[cli]) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio>=4.5->mcp[cli]) (4.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.1->mcp[cli]) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.1->mcp[cli]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.1->mcp[cli]) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp[cli]) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp[cli]) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp[cli]) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp[cli]) (0.28.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.11.0->mcp[cli]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.11.0->mcp[cli]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.11.0->mcp[cli]) (0.4.2)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp[cli]) (43.0.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.16.0->mcp[cli]) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.16.0->mcp[cli]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.16.0->mcp[cli]) (13.9.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp[cli]) (2.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer>=0.16.0->mcp[cli]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer>=0.16.0->mcp[cli]) (2.19.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp[cli]) (2.23)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.16.0->mcp[cli]) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd mcp-server-demo\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y01caku9zQh6",
        "outputId": "a9378242-f4f3-492a-9fe4-998328709874"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cd: mcp-server-demo: No such file or directory\n",
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd mcp-server-demo && uv add langchain-google-genai langgraph"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LbRRLnnzUub",
        "outputId": "5d7cd541-0204-4d1d-d8cd-e4077a731926"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cd: mcp-server-demo: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.tools import Tool\n",
        "from langgraph.graph import StateGraph, END\n",
        "from IPython.display import display, HTML\n",
        "from typing import TypedDict\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "from mcp.server.fastmcp import FastMCP\n",
        "from google.colab import userdata\n",
        "from langsmith import traceable\n",
        "from google.colab import userdata\n",
        "\n",
        "# Import APl Key.\n",
        "api_key = userdata.get(\"Ben856\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"Ben856 secret not found. Please set your API key in Colab Secrets.\")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "\n",
        "# Agent State Definition.\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "   input: str\n",
        "   output: str\n",
        "   trace_id: str\n",
        "   context: dict\n",
        "\n",
        "# Prompt Template.\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a strategic AI agent assisting with the development of Arctic Sentinel—an AI-native ISR dashboard for Arctic vulnerability mapping.\n",
        "Respond with modular, secure, and expressive outputs tailored for employer engagement and demo impact. Input: {input}\n",
        "\"\"\")\n",
        "\n",
        "# Tools Definition.\n",
        "\n",
        "def telemetry_tool(input: str) -> str:\n",
        "    return f\"Telemetry captured for input: {input}\"\n",
        "\n",
        "def overlay_tool(input: str) -> str:\n",
        "    return f\"Overlay captured for input: {input}\"\n",
        "\n",
        "def arcgis_tool(input: str) -> str:\n",
        "    map_url = \"https://www.arcgis.com/apps/mapviewer/index.html?webmap=6d8144399610426e8f57246e2607782d\"\n",
        "    return f\"View Arctic vulnerability map: <a href='{map_url}' target='_blank'>ArcGIS Viewer</a>\"\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(name=\"telemetry\", func=telemetry_tool, description=\"Secure telemetry capture\"),\n",
        "    Tool.from_function(name=\"overlay\", func=overlay_tool, description=\"Narrative overlay generation\"),\n",
        "    Tool.from_function(name=\"arcgis\", func=arcgis_tool, description=\"Link to Arctic vulnerability map\")\n",
        "]\n",
        "\n",
        "# Initialize Gemini Model.\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", api_key=api_key)\n",
        "\n",
        "# LangGrap nodes.\n",
        "@traceable(name=\"entry_node\")\n",
        "def entry_node(state: AgentState) -> AgentState:\n",
        "    return {**state, \"trace_id\": f\"trace-{random.randint(1000,9999)}\"}\n",
        "\n",
        "@traceable(name=\"llm_node\")\n",
        "def llm_node(state: AgentState) -> AgentState:\n",
        "    response = llm.invoke(prompt.format(input=state[\"input\"]))\n",
        "    return {**state, \"output\": response.content}\n",
        "\n",
        "@traceable(name=\"tool_node\")\n",
        "def tool_node(state: AgentState) -> AgentState:\n",
        "    telemetry = telemetry_tool(state[\"input\"])\n",
        "    overlay = overlay_tool(state[\"input\"])\n",
        "    arcgis = arcgis_tool(state[\"input\"])\n",
        "    return {**state, \"context\": {\n",
        "        \"telemetry\": telemetry,\n",
        "        \"overlay\": overlay,\n",
        "        \"arcgis\": arcgis\n",
        "    }}\n",
        "\n",
        "@traceable(name=\"display_node\")\n",
        "def display_node(state: AgentState) -> AgentState:\n",
        "    html = f\"\"\"\n",
        "    <div style='font-family:sans-serif;'>\n",
        "        <h2>Agent Output</h2>\n",
        "        <p><strong>Response:</strong> {state['output']}</p>\n",
        "        <p><strong>Telemetry:</strong> {state['context']['telemetry']}</p>\n",
        "        <p><strong>Overlay:</strong> {state['context']['overlay']}</p>\n",
        "        <p><strong>Map Viewer:</strong> {state['context']['arcgis']}</p>\n",
        "        <p><strong>Trace ID:</strong> {state['trace_id']}</p>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    display(HTML(html))\n",
        "    return state\n",
        "\n",
        "# LangGraph workflow.\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"entry\", entry_node)\n",
        "graph.add_node(\"llm\", llm_node)\n",
        "graph.add_node(\"tools\", tool_node)\n",
        "graph.add_node(\"display\", display_node)\n",
        "\n",
        "graph.set_entry_point(\"entry\")\n",
        "graph.add_edge(\"entry\", \"llm\")\n",
        "graph.add_edge(\"llm\", \"tools\")\n",
        "graph.add_edge(\"tools\", \"display\")\n",
        "graph.add_edge(\"display\", END)\n",
        "\n",
        "# Compile app.\n",
        "agent_executor = graph.compile()\n",
        "\n",
        "# Run agent.\n",
        "agent_executor.invoke({\"input\": \"Generate a modular demo script for Arctic Sentinel, tailored for stakeholder engagement and technical impact\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oeE8a-7Uzfn-",
        "outputId": "3f3a0b5f-3d5f-4ad4-e14a-a179b33455ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style='font-family:sans-serif;'>\n",
              "        <h2>Agent Output</h2>\n",
              "        <p><strong>Response:</strong> Okay, here is a modular, secure, and expressive demo script for Arctic Sentinel, designed to maximize employer engagement and technical impact.\n",
              "\n",
              "---\n",
              "\n",
              "## Arctic Sentinel: AI-Native ISR Dashboard Demo Script\n",
              "\n",
              "**Target Audience:** Strategic Stakeholders, Technical Leads, Potential Investors\n",
              "**Goal:** Showcase Arctic Sentinel's strategic value, technical sophistication, modular architecture, and robust security.\n",
              "**Duration:** ~15-20 minutes (flexible, with optional deep-dives)\n",
              "\n",
              "---\n",
              "\n",
              "### **Module 1: Strategic Imperative & Vision (The \"Why\")**\n",
              "*(Presenter: Sets the stage, passionate and authoritative)*\n",
              "\n",
              "**[0:00 - 2:00]**\n",
              "\n",
              "**Presenter:** \"Good morning/afternoon. We are here today to introduce you to **Arctic Sentinel** – our vision for securing the future of the Arctic. The Arctic is no longer a remote frontier; it's a rapidly evolving geopolitical and environmental hotspot. Melting ice opens new shipping lanes, exposes critical resources, and creates unprecedented vulnerabilities – from infrastructure integrity to national security.\"\n",
              "\n",
              "\"Traditional ISR (Intelligence, Surveillance, and Reconnaissance) methods struggle with the Arctic's vastness, extreme conditions, and data sparsity. This is where Arctic Sentinel steps in. We've engineered an **AI-native ISR dashboard** specifically to provide comprehensive, real-time vulnerability mapping across this critical domain.\"\n",
              "\n",
              "\"Our mission with Arctic Sentinel is to transform raw, disparate data into **actionable intelligence**, offering unparalleled situational awareness and predictive capabilities. It’s built from the ground up to be modular, secure, and scalable – ready for the challenges of tomorrow.\"\n",
              "\n",
              "---\n",
              "\n",
              "### **Module 2: The Core: Data Ingestion & Fusion Engine (The \"Brain\")**\n",
              "*(Presenter: Transitions to the platform, highlights data sources and architecture)*\n",
              "*(Visual: Dashboard showing diverse data feeds converging, possibly a high-level architectural diagram briefly)*\n",
              "\n",
              "**[2:00 - 5:00]**\n",
              "\n",
              "**Presenter:** \"Let's dive into the heart of Arctic Sentinel. At its foundation is our **Data Ingestion and Fusion Engine**. The Arctic is a data-rich environment, but the data is fragmented across countless sources. Our engine is designed to securely ingest, normalize, and fuse this diverse information in real-time.\"\n",
              "\n",
              "\"Notice on the screen, the variety of data streams we are processing:\n",
              "*   **Satellite Imagery:** High-resolution optical and SAR (Synthetic Aperture Radar) data for ice movement, vessel tracking, and infrastructure monitoring.\n",
              "*   **Environmental Sensors:** Real-time data from buoys, weather stations, and subsea sensors on ocean currents, temperature, and seismic activity.\n",
              "*   **Maritime AIS/LRIT:** Global shipping traffic, vessel identities, and routes.\n",
              "*   **Geopolitical & OSINT Feeds:** News, social media, and open-source intelligence for emerging threats or activities.\n",
              "*   **Cyber Threat Intelligence:** Data streams identifying potential cyber vulnerabilities targeting Arctic infrastructure.\"\n",
              "\n",
              "\"**Technical Impact:** This module is built on a **microservices architecture**, leveraging secure, containerized APIs for each data source. This ensures **modularity** – new data streams can be integrated rapidly without disrupting the core system. Our data pipeline employs **end-to-end encryption** (both at rest and in transit) and **data anonymization techniques** where appropriate, adhering to a **zero-trust security model** from the moment data enters the system. This modularity also translates to **unprecedented scalability**, allowing us to process petabytes of data as the Arctic's strategic importance grows.\"\n",
              "\n",
              "---\n",
              "\n",
              "### **Module 3: AI-Powered Vulnerability Analysis (The \"Insight Generator\")**\n",
              "*(Presenter: Demonstrates AI features, focuses on actionable intelligence)*\n",
              "*(Visual: Dashboard shifts to show AI-generated insights: anomaly detection, predictive models, risk scores overlayed on maps)*\n",
              "\n",
              "**[5:00 - 10:00]**\n",
              "\n",
              "**Presenter:** \"Ingesting data is one thing; extracting meaning is another. This is where Arctic Sentinel's **AI-native capabilities** truly shine. Our **Vulnerability Analysis Module** transforms raw data into actionable intelligence, moving beyond mere observation to **prediction and proactive threat identification**.\"\n",
              "\n",
              "\"Observe how our dashboard dynamically highlights areas of concern. This is driven by several sophisticated AI models:\n",
              "*   **Predictive Ice Dynamics:** Using deep learning, we forecast ice melt, opening/closing of shipping lanes, and potential hazards to maritime navigation and offshore infrastructure. (Show a time-lapse prediction).\n",
              "*   **Anomaly Detection:** Our machine learning algorithms continuously monitor all data streams for unusual patterns. For example, a vessel deviating from known routes, unusual energy signatures, or sudden spikes in cyber activity targeting a specific region. (Highlight an anomalous vessel track or a flagged cyber event).\n",
              "*   **Infrastructure Stress Assessment:** By correlating satellite imagery, sensor data, and weather patterns, we predict potential stress points or failures in critical infrastructure like pipelines, communication cables, or research stations due to environmental factors or external threats. (Show a simulated infrastructure vulnerability score).\n",
              "*   **Geopolitical Risk Scoring:** Our NLP models process unstructured OSINT data to identify escalating geopolitical tensions or emerging threats, assigning dynamic risk scores to specific Arctic regions. (Show a region with a high-risk score and associated contributing factors).\n",
              "\n",
              "\"**Technical Impact:** Each analytical capability is a distinct, independently deployable service, allowing for continuous integration and deployment of new models. We utilize **federated learning** where sensitive data must remain localized, enhancing privacy and security. Our AI models are built with **explainable AI (XAI)** principles in mind, providing transparency into *why* a certain vulnerability or anomaly has been flagged, fostering trust and enabling faster decision-making for operators. This isn't just data visualization; it's **proactive, intelligent vulnerability mapping**.\"\n",
              "\n",
              "---\n",
              "\n",
              "### **Module 4: Interactive Geospatial Dashboard & Collaboration (The \"Action Hub\")**\n",
              "*(Presenter: Showcases UX, customization, and secure sharing)*\n",
              "*(Visual: Interactive map, drill-down features, alert system, collaboration tools)*\n",
              "\n",
              "**[10:00 - 14:00]**\n",
              "\n",
              "**Presenter:** \"All these powerful insights are meaningless without an intuitive, secure interface for decision-makers. Our **Interactive Geospatial Dashboard** is designed for clarity and control.\"\n",
              "\n",
              "\"On the screen, you see a high-resolution, multi-layered map of the Arctic. Users can:\n",
              "*   **Customize Layers:** Toggle various data overlays – ice concentration, vessel traffic, infrastructure locations, environmental data, and AI-generated vulnerability heatmaps. (Demonstrate adding/removing layers).\n",
              "*   **Drill-Down Capabilities:** Click on any anomaly or region of interest to access detailed reports, historical data, and contributing AI analysis. (Click on an anomaly and show its detailed report).\n",
              "*   **Time-Series Analysis:** Rewind or fast-forward through historical data and predictive forecasts to understand trends and project future scenarios. (Demonstrate time-slider).\n",
              "*   **Alert & Notification System:** Configure custom alerts based on specific thresholds or detected anomalies, delivered securely to relevant personnel. (Show an example alert notification).\n",
              "\n",
              "\"Furthermore, **secure collaboration** is paramount. Arctic Sentinel integrates:\n",
              "*   **Role-Based Access Control (RBAC):** Granular permissions ensure users only see data relevant to their role and security clearance.\n",
              "*   **Secure Communication Channels:** Integrated encrypted messaging and annotation tools allow teams to discuss findings directly within the platform, maintaining a chain of custody and audit trail.\n",
              "*   **Dynamic Report Generation:** Generate customizable, secure reports with embedded data and AI insights for stakeholder briefings.\n",
              "\n",
              "\"**Technical Impact:** The front-end is built using modern, responsive frameworks ensuring optimal performance across various devices. All interactions with the backend are secured via **OAuth 2.0** and **JWT (JSON Web Tokens)**, with every user action meticulously logged for **auditing and compliance**. Our secure collaboration features are underpinned by **end-to-end encryption** for all communications and shared assets, ensuring that sensitive intelligence remains protected. This module emphasizes **expressiveness** – making complex data intuitive, and **security** – making collaboration safe.\"\n",
              "\n",
              "---\n",
              "\n",
              "### **Module 5: Architecture, Security & Future Vision (The \"How\" & \"Next\")**\n",
              "*(Presenter: Reiterate key strengths, look ahead, call to action)*\n",
              "*(Visual: High-level architectural diagram highlighting security points, then back to the main dashboard)*\n",
              "\n",
              "**[14:00 - 17:00]**\n",
              "\n",
              "**Presenter:** \"To summarize the robust foundation of Arctic Sentinel:\n",
              "*   **Modular Architecture:** Built on **cloud-agnostic microservices and Kubernetes**, ensuring portability, resilience, and rapid feature development.\n",
              "*   **Security-First Design:** Implements **Zero-Trust principles**, **multi-factor authentication (MFA)**, **data encryption at all stages**, continuous security monitoring, and adherence to industry-leading compliance standards (e.g., NIST, ISO 27001). Every component is hardened and regularly audited.\n",
              "*   **AI-Native:** Not just AI-enabled, but fundamentally designed around intelligent automation, predictive analytics, and continuous learning to deliver proactive insights.\"\n",
              "\n",
              "\"Looking ahead, Arctic Sentinel is designed for continuous evolution. We envision integration with emerging technologies like quantum-resistant cryptography, advanced drone ISR assets for hyper-local data collection, and even sophisticated simulation environments for scenario planning.\"\n",
              "\n",
              "\"Arctic Sentinel isn't just a dashboard; it's a strategic asset. It's the future of Arctic intelligence – providing the clarity, foresight, and security needed to navigate this critical domain.\"\n",
              "\n",
              "---\n",
              "\n",
              "### **Module 6: Call to Action & Q&A**\n",
              "*(Presenter: Opens the floor)*\n",
              "\n",
              "**[17:00 - 20:00+]**\n",
              "\n",
              "**Presenter:** \"We believe Arctic Sentinel represents a significant leap forward in ISR capabilities for the Arctic. We are eager to discuss how this platform can be tailored to meet your specific operational needs and strategic objectives. Thank you.\"\n",
              "\n",
              "\"I'd now like to open the floor for any questions you might have.\"\n",
              "\n",
              "---</p>\n",
              "        <p><strong>Telemetry:</strong> Telemetry captured for input: Generate a modular demo script for Arctic Sentinel, tailored for stakeholder engagement and technical impact</p>\n",
              "        <p><strong>Overlay:</strong> Overlay captured for input: Generate a modular demo script for Arctic Sentinel, tailored for stakeholder engagement and technical impact</p>\n",
              "        <p><strong>Map Viewer:</strong> View Arctic vulnerability map: <a href='https://www.arcgis.com/apps/mapviewer/index.html?webmap=6d8144399610426e8f57246e2607782d' target='_blank'>ArcGIS Viewer</a></p>\n",
              "        <p><strong>Trace ID:</strong> trace-5623</p>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Generate a modular demo script for Arctic Sentinel, tailored for stakeholder engagement and technical impact',\n",
              " 'output': 'Okay, here is a modular, secure, and expressive demo script for Arctic Sentinel, designed to maximize employer engagement and technical impact.\\n\\n---\\n\\n## Arctic Sentinel: AI-Native ISR Dashboard Demo Script\\n\\n**Target Audience:** Strategic Stakeholders, Technical Leads, Potential Investors\\n**Goal:** Showcase Arctic Sentinel\\'s strategic value, technical sophistication, modular architecture, and robust security.\\n**Duration:** ~15-20 minutes (flexible, with optional deep-dives)\\n\\n---\\n\\n### **Module 1: Strategic Imperative & Vision (The \"Why\")**\\n*(Presenter: Sets the stage, passionate and authoritative)*\\n\\n**[0:00 - 2:00]**\\n\\n**Presenter:** \"Good morning/afternoon. We are here today to introduce you to **Arctic Sentinel** – our vision for securing the future of the Arctic. The Arctic is no longer a remote frontier; it\\'s a rapidly evolving geopolitical and environmental hotspot. Melting ice opens new shipping lanes, exposes critical resources, and creates unprecedented vulnerabilities – from infrastructure integrity to national security.\"\\n\\n\"Traditional ISR (Intelligence, Surveillance, and Reconnaissance) methods struggle with the Arctic\\'s vastness, extreme conditions, and data sparsity. This is where Arctic Sentinel steps in. We\\'ve engineered an **AI-native ISR dashboard** specifically to provide comprehensive, real-time vulnerability mapping across this critical domain.\"\\n\\n\"Our mission with Arctic Sentinel is to transform raw, disparate data into **actionable intelligence**, offering unparalleled situational awareness and predictive capabilities. It’s built from the ground up to be modular, secure, and scalable – ready for the challenges of tomorrow.\"\\n\\n---\\n\\n### **Module 2: The Core: Data Ingestion & Fusion Engine (The \"Brain\")**\\n*(Presenter: Transitions to the platform, highlights data sources and architecture)*\\n*(Visual: Dashboard showing diverse data feeds converging, possibly a high-level architectural diagram briefly)*\\n\\n**[2:00 - 5:00]**\\n\\n**Presenter:** \"Let\\'s dive into the heart of Arctic Sentinel. At its foundation is our **Data Ingestion and Fusion Engine**. The Arctic is a data-rich environment, but the data is fragmented across countless sources. Our engine is designed to securely ingest, normalize, and fuse this diverse information in real-time.\"\\n\\n\"Notice on the screen, the variety of data streams we are processing:\\n*   **Satellite Imagery:** High-resolution optical and SAR (Synthetic Aperture Radar) data for ice movement, vessel tracking, and infrastructure monitoring.\\n*   **Environmental Sensors:** Real-time data from buoys, weather stations, and subsea sensors on ocean currents, temperature, and seismic activity.\\n*   **Maritime AIS/LRIT:** Global shipping traffic, vessel identities, and routes.\\n*   **Geopolitical & OSINT Feeds:** News, social media, and open-source intelligence for emerging threats or activities.\\n*   **Cyber Threat Intelligence:** Data streams identifying potential cyber vulnerabilities targeting Arctic infrastructure.\"\\n\\n\"**Technical Impact:** This module is built on a **microservices architecture**, leveraging secure, containerized APIs for each data source. This ensures **modularity** – new data streams can be integrated rapidly without disrupting the core system. Our data pipeline employs **end-to-end encryption** (both at rest and in transit) and **data anonymization techniques** where appropriate, adhering to a **zero-trust security model** from the moment data enters the system. This modularity also translates to **unprecedented scalability**, allowing us to process petabytes of data as the Arctic\\'s strategic importance grows.\"\\n\\n---\\n\\n### **Module 3: AI-Powered Vulnerability Analysis (The \"Insight Generator\")**\\n*(Presenter: Demonstrates AI features, focuses on actionable intelligence)*\\n*(Visual: Dashboard shifts to show AI-generated insights: anomaly detection, predictive models, risk scores overlayed on maps)*\\n\\n**[5:00 - 10:00]**\\n\\n**Presenter:** \"Ingesting data is one thing; extracting meaning is another. This is where Arctic Sentinel\\'s **AI-native capabilities** truly shine. Our **Vulnerability Analysis Module** transforms raw data into actionable intelligence, moving beyond mere observation to **prediction and proactive threat identification**.\"\\n\\n\"Observe how our dashboard dynamically highlights areas of concern. This is driven by several sophisticated AI models:\\n*   **Predictive Ice Dynamics:** Using deep learning, we forecast ice melt, opening/closing of shipping lanes, and potential hazards to maritime navigation and offshore infrastructure. (Show a time-lapse prediction).\\n*   **Anomaly Detection:** Our machine learning algorithms continuously monitor all data streams for unusual patterns. For example, a vessel deviating from known routes, unusual energy signatures, or sudden spikes in cyber activity targeting a specific region. (Highlight an anomalous vessel track or a flagged cyber event).\\n*   **Infrastructure Stress Assessment:** By correlating satellite imagery, sensor data, and weather patterns, we predict potential stress points or failures in critical infrastructure like pipelines, communication cables, or research stations due to environmental factors or external threats. (Show a simulated infrastructure vulnerability score).\\n*   **Geopolitical Risk Scoring:** Our NLP models process unstructured OSINT data to identify escalating geopolitical tensions or emerging threats, assigning dynamic risk scores to specific Arctic regions. (Show a region with a high-risk score and associated contributing factors).\\n\\n\"**Technical Impact:** Each analytical capability is a distinct, independently deployable service, allowing for continuous integration and deployment of new models. We utilize **federated learning** where sensitive data must remain localized, enhancing privacy and security. Our AI models are built with **explainable AI (XAI)** principles in mind, providing transparency into *why* a certain vulnerability or anomaly has been flagged, fostering trust and enabling faster decision-making for operators. This isn\\'t just data visualization; it\\'s **proactive, intelligent vulnerability mapping**.\"\\n\\n---\\n\\n### **Module 4: Interactive Geospatial Dashboard & Collaboration (The \"Action Hub\")**\\n*(Presenter: Showcases UX, customization, and secure sharing)*\\n*(Visual: Interactive map, drill-down features, alert system, collaboration tools)*\\n\\n**[10:00 - 14:00]**\\n\\n**Presenter:** \"All these powerful insights are meaningless without an intuitive, secure interface for decision-makers. Our **Interactive Geospatial Dashboard** is designed for clarity and control.\"\\n\\n\"On the screen, you see a high-resolution, multi-layered map of the Arctic. Users can:\\n*   **Customize Layers:** Toggle various data overlays – ice concentration, vessel traffic, infrastructure locations, environmental data, and AI-generated vulnerability heatmaps. (Demonstrate adding/removing layers).\\n*   **Drill-Down Capabilities:** Click on any anomaly or region of interest to access detailed reports, historical data, and contributing AI analysis. (Click on an anomaly and show its detailed report).\\n*   **Time-Series Analysis:** Rewind or fast-forward through historical data and predictive forecasts to understand trends and project future scenarios. (Demonstrate time-slider).\\n*   **Alert & Notification System:** Configure custom alerts based on specific thresholds or detected anomalies, delivered securely to relevant personnel. (Show an example alert notification).\\n\\n\"Furthermore, **secure collaboration** is paramount. Arctic Sentinel integrates:\\n*   **Role-Based Access Control (RBAC):** Granular permissions ensure users only see data relevant to their role and security clearance.\\n*   **Secure Communication Channels:** Integrated encrypted messaging and annotation tools allow teams to discuss findings directly within the platform, maintaining a chain of custody and audit trail.\\n*   **Dynamic Report Generation:** Generate customizable, secure reports with embedded data and AI insights for stakeholder briefings.\\n\\n\"**Technical Impact:** The front-end is built using modern, responsive frameworks ensuring optimal performance across various devices. All interactions with the backend are secured via **OAuth 2.0** and **JWT (JSON Web Tokens)**, with every user action meticulously logged for **auditing and compliance**. Our secure collaboration features are underpinned by **end-to-end encryption** for all communications and shared assets, ensuring that sensitive intelligence remains protected. This module emphasizes **expressiveness** – making complex data intuitive, and **security** – making collaboration safe.\"\\n\\n---\\n\\n### **Module 5: Architecture, Security & Future Vision (The \"How\" & \"Next\")**\\n*(Presenter: Reiterate key strengths, look ahead, call to action)*\\n*(Visual: High-level architectural diagram highlighting security points, then back to the main dashboard)*\\n\\n**[14:00 - 17:00]**\\n\\n**Presenter:** \"To summarize the robust foundation of Arctic Sentinel:\\n*   **Modular Architecture:** Built on **cloud-agnostic microservices and Kubernetes**, ensuring portability, resilience, and rapid feature development.\\n*   **Security-First Design:** Implements **Zero-Trust principles**, **multi-factor authentication (MFA)**, **data encryption at all stages**, continuous security monitoring, and adherence to industry-leading compliance standards (e.g., NIST, ISO 27001). Every component is hardened and regularly audited.\\n*   **AI-Native:** Not just AI-enabled, but fundamentally designed around intelligent automation, predictive analytics, and continuous learning to deliver proactive insights.\"\\n\\n\"Looking ahead, Arctic Sentinel is designed for continuous evolution. We envision integration with emerging technologies like quantum-resistant cryptography, advanced drone ISR assets for hyper-local data collection, and even sophisticated simulation environments for scenario planning.\"\\n\\n\"Arctic Sentinel isn\\'t just a dashboard; it\\'s a strategic asset. It\\'s the future of Arctic intelligence – providing the clarity, foresight, and security needed to navigate this critical domain.\"\\n\\n---\\n\\n### **Module 6: Call to Action & Q&A**\\n*(Presenter: Opens the floor)*\\n\\n**[17:00 - 20:00+]**\\n\\n**Presenter:** \"We believe Arctic Sentinel represents a significant leap forward in ISR capabilities for the Arctic. We are eager to discuss how this platform can be tailored to meet your specific operational needs and strategic objectives. Thank you.\"\\n\\n\"I\\'d now like to open the floor for any questions you might have.\"\\n\\n---',\n",
              " 'trace_id': 'trace-5623',\n",
              " 'context': {'telemetry': 'Telemetry captured for input: Generate a modular demo script for Arctic Sentinel, tailored for stakeholder engagement and technical impact',\n",
              "  'overlay': 'Overlay captured for input: Generate a modular demo script for Arctic Sentinel, tailored for stakeholder engagement and technical impact',\n",
              "  'arcgis': \"View Arctic vulnerability map: <a href='https://www.arcgis.com/apps/mapviewer/index.html?webmap=6d8144399610426e8f57246e2607782d' target='_blank'>ArcGIS Viewer</a>\"}}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}